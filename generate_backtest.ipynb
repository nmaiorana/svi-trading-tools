{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci-Kit version: 1.1.3\n",
      "Sci-Kit version: 1.1.3\n",
      "2022-11-27 15:00:06,947|GenerateBacktest|INFO|Python version: 3.8.15\n",
      "2022-11-27 15:00:06,948|GenerateBacktest|INFO|Pandas version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "logging.config.fileConfig('./config/logging.ini')\n",
    "logger = logging.getLogger('GenerateBacktest')\n",
    "\n",
    "import configparser\n",
    "from platform import python_version\n",
    "from pathlib import Path\n",
    "\n",
    "# Project imports\n",
    "import importlib\n",
    "import tools.trading_factors_yahoo as alpha_factors\n",
    "importlib.reload(alpha_factors)\n",
    "import tools.utils as utils\n",
    "importlib.reload(utils)\n",
    "import tools.nonoverlapping_estimator as ai_estimator\n",
    "importlib.reload(ai_estimator)\n",
    "import tools.portfolio_optimizer as portfolio_optimizer\n",
    "importlib.reload(portfolio_optimizer)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "logger.info(f'Python version: {python_version()}')\n",
    "logger.info(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "default_config = config['BackTest']\n",
    "ai_alpha_config = config['AIAlpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History data and Alphs Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 15:00:14,203|GenerateBacktest|INFO|PRICE_HISTORIES_FILE|./data/price_histories_yahoo.csv...\n",
      "You have 501 stocks from picing\n",
      "2022-11-27 15:00:15,420|GenerateBacktest|INFO|ALPHA_VECTORS_FILE|./data/alpha_vectors.csv...\n",
      "2022-11-27 15:00:15,654|GenerateBacktest|INFO|ALPHA_VECTORS_STOCKS|501\n",
      "2022-11-27 15:00:15,655|GenerateBacktest|INFO|BEATA_FACTORS_FILE|./data/daily_beta.pickle...\n",
      "2022-11-27 15:00:17,418|GenerateBacktest|INFO|DAILY_BETAS|1008\n",
      "2022-11-27 15:00:17,419|GenerateBacktest|INFO|OPT|risk_cap|0.08\n",
      "2022-11-27 15:00:17,420|GenerateBacktest|INFO|OPT|weights_max|0.15\n",
      "2022-11-27 15:00:17,420|GenerateBacktest|INFO|OPT|weights_min|0.0\n"
     ]
    }
   ],
   "source": [
    "price_histories_file_name = default_config['DataDirectory'] + '/' + default_config['PriceHistoriesFileName']\n",
    "ai_alpha_factors_file_name = default_config['DataDirectory'] + '/' + default_config['AIAlphaFileName']\n",
    "beta_factors_file_name = default_config[\"DataDirectory\"] + '/' + default_config['BetaFactorsFileName']\n",
    "\n",
    "\n",
    "logger.info(f'PRICE_HISTORIES_FILE|{price_histories_file_name}...')\n",
    "price_histories = pd.read_csv(price_histories_file_name, header=[0, 1], index_col=[0], parse_dates=True, low_memory=False)\n",
    "pricing = price_histories.Close\n",
    "adv = alpha_factors.AverageDollarVolume(price_histories, 5).factor_data\n",
    "print(f'You have {len(pricing.columns)} stocks from picing')\n",
    "\n",
    "logger.info(f'ALPHA_VECTORS_FILE|{ai_alpha_factors_file_name}...')\n",
    "alpha_vectors = pd.read_csv(ai_alpha_factors_file_name, parse_dates=['Date']).set_index(['Date']).sort_index()\n",
    "logger.info(f'ALPHA_VECTORS_STOCKS|{len(alpha_vectors.columns)}')\n",
    "\n",
    "logger.info(f'BEATA_FACTORS_FILE|{beta_factors_file_name}...')\n",
    "with open(beta_factors_file_name, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    daily_betas = pickle.load(f)\n",
    "logger.info(f'DAILY_BETAS|{len(daily_betas)}')\n",
    "\n",
    "risk_cap = float(default_config['risk_cap'])\n",
    "weights_max = float(default_config['weights_max'])\n",
    "weights_min = float(default_config['weights_min'])\n",
    "\n",
    "logger.info(f'OPT|risk_cap|{risk_cap}')\n",
    "logger.info(f'OPT|weights_max|{weights_max}')\n",
    "logger.info(f'OPT|weights_min|{weights_min}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda(average_dollar_volume):\n",
    "    adv = average_dollar_volume.replace(np.nan, 1.0e4)\n",
    "    adv = adv.replace(0.0, 1.0e4)\n",
    "    return 0.1 / adv\n",
    "\n",
    "def get_total_transaction_costs(h0, h_star, tc_lambda):\n",
    "    return np.dot( (h_star - h0) ** 2, tc_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back test AI Alpha and Daily Betas to produce optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-27 15:00:25,546|GenerateBacktest|INFO|OPT|2021-11-26 00:00:00|2022-11-17 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9962166b023f40d8afdb6a75d189f863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dates:   0%|          | 0/50 [00:00<?, ? Portfolio Optimization/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "returns = alpha_factors.FactorReturns(price_histories).factor_data\n",
    "dlyreturn_n_days_delay = int(ai_alpha_config['ForwardPredictionDays'])\n",
    "delayed_returns = returns[-252:].shift(-dlyreturn_n_days_delay).dropna()\n",
    "start_date = list(delayed_returns.index)[0]\n",
    "end_date = list(delayed_returns.index)[-1]\n",
    "logger.info(f'OPT|{start_date}|{end_date}')\n",
    "tc_lambda = get_lambda(adv)\n",
    "\n",
    "current_holdings = pd.Series(np.zeros(len(delayed_returns.columns)), index=delayed_returns.columns)\n",
    "\n",
    "min_viable_port_return = float(default_config['min_viable_port_return'])\n",
    "opt_date_returns = {}\n",
    "opt_date_tc = {}\n",
    "for opt_date in tqdm(delayed_returns.index.to_list()[-252::dlyreturn_n_days_delay], desc='Dates', unit=' Portfolio Optimization'):\n",
    "    alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "    risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "    est_return = delayed_returns.loc[opt_date]\n",
    "    optimal_weights = portfolio_optimizer.OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)\n",
    "    new_holdings = optimal_weights['optimalWeights']\n",
    "    opt_date_returns[opt_date] = (new_holdings * est_return).sum()\n",
    "    # trading costs\n",
    "    opt_date_tc[opt_date] = get_total_transaction_costs(current_holdings, new_holdings, tc_lambda.loc[opt_date])\n",
    "    current_holdings = new_holdings\n",
    "\n",
    "port_return = round(np.sum(list(opt_date_returns.values())) * 100, 2)\n",
    "logger.info(f'OPT_PORT_RETURN|{port_return}%')\n",
    "pd.Series(opt_date_returns).cumsum().plot()\n",
    "if port_return >= min_viable_port_return:\n",
    "    logger.info(f'OPT|PROCEED|{port_return}%')\n",
    "else:\n",
    "    logger.warn(f'OPT|STOP|{port_return}')\n",
    "    raise RuntimeError(f'Backtest indicates this strategy needs more work! ({port_return})') from None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_ser = pd.Series(opt_date_tc)\n",
    "re_ser = pd.Series(opt_date_returns)\n",
    "net_ret = re_ser + tc_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ret.cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(net_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(re_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TODO:\n",
    "\n",
    "- For go forward situations, save all the information to be used to put in buy/sell orders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
