{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 19:50:03,045|numexpr.utils|INFO|NumExpr defaulting to 4 threads.\n",
      "Sci-Kit version: 0.24.1\n",
      "Sci-Kit version: 0.24.1\n",
      "2022-05-15 19:50:06,668|GenerateBacktest|INFO|Python version: 3.8.8\n",
      "2022-05-15 19:50:06,668|GenerateBacktest|INFO|Pandas version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "logging.config.fileConfig('./config/logging.ini')\n",
    "logger = logging.getLogger('GenerateBacktest')\n",
    "\n",
    "import configparser\n",
    "from platform import python_version\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the import path for the project tools directiory\n",
    "import sys\n",
    "# insert at position 1 in the path, as 0 is the path of this file.\n",
    "sys.path.insert(1, 'tools')\n",
    "\n",
    "# Project imports\n",
    "import importlib\n",
    "import trading_factors_yahoo as alpha_factors\n",
    "importlib.reload(alpha_factors)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import nonoverlapping_estimator as ai_estimator\n",
    "importlib.reload(ai_estimator)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "logger.info(f'Python version: {python_version()}')\n",
    "logger.info(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "default_config = config['BackTest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History data and Alphs Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 19:50:06,725|GenerateBacktest|INFO|PRICE_HISTORIES_FILE|./data/price_histories_yahoo.csv...\n",
      "You have 501 stocks from picing\n",
      "2022-05-15 19:50:07,768|GenerateBacktest|INFO|ALPHA_VECTORS_FILE|./data/pre_backtest_alpha_vectors.csv...\n",
      "2022-05-15 19:50:07,935|GenerateBacktest|INFO|ALPHA_VECTORS_STOCKS|501\n",
      "2022-05-15 19:50:07,935|GenerateBacktest|INFO|BEATA_FACTORS_FILE|./data/daily_beta.pickle...\n",
      "2022-05-15 19:50:09,684|GenerateBacktest|INFO|DAILY_BETAS|1009\n",
      "2022-05-15 19:50:09,684|GenerateBacktest|INFO|OPT|risk_cap|0.15\n",
      "2022-05-15 19:50:09,684|GenerateBacktest|INFO|OPT|weights_max|0.125\n",
      "2022-05-15 19:50:09,684|GenerateBacktest|INFO|OPT|weights_min|0.0\n"
     ]
    }
   ],
   "source": [
    "price_histories_file_name = default_config['DataDirectory'] + '/' + default_config['PriceHistoriesFileName']\n",
    "ai_alpha_factors_file_name = default_config['DataDirectory'] + '/' + default_config['AIAlphaFileName']\n",
    "beta_factors_file_name = default_config[\"DataDirectory\"] + '/' + default_config['BetaFactorsFileName']\n",
    "\n",
    "\n",
    "logger.info(f'PRICE_HISTORIES_FILE|{price_histories_file_name}...')\n",
    "price_histories = pd.read_csv(price_histories_file_name, header=[0, 1], index_col=[0], parse_dates=True, low_memory=False)\n",
    "pricing = price_histories.Close\n",
    "print(f'You have {len(pricing.columns)} stocks from picing')\n",
    "\n",
    "logger.info(f'ALPHA_VECTORS_FILE|{ai_alpha_factors_file_name}...')\n",
    "alpha_vectors = pd.read_csv(ai_alpha_factors_file_name, parse_dates=['Date']).set_index(['Date']).sort_index()\n",
    "logger.info(f'ALPHA_VECTORS_STOCKS|{len(alpha_vectors.columns)}')\n",
    "\n",
    "logger.info(f'BEATA_FACTORS_FILE|{beta_factors_file_name}...')\n",
    "with open(beta_factors_file_name, 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    daily_betas = pickle.load(f)\n",
    "logger.info(f'DAILY_BETAS|{len(daily_betas)}')\n",
    "\n",
    "risk_cap = float(default_config['risk_cap'])\n",
    "weights_max = float(default_config['weights_max'])\n",
    "weights_min = float(default_config['weights_min'])\n",
    "\n",
    "logger.info(f'OPT|risk_cap|{risk_cap}')\n",
    "logger.info(f'OPT|weights_max|{weights_max}')\n",
    "logger.info(f'OPT|weights_min|{weights_min}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back test AI Alpha and Daily Betas to produce optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15 19:50:09,760|GenerateBacktest|INFO|OPT|2021-05-17 00:00:00|2022-05-06 00:00:00\n",
      "2022-05-15 19:50:09,761|GenerateBacktest|INFO|OPT|INIT_PORT_VALUE|100000.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dc7b687d0342528260a0bb9fa571ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dates:   0%|          | 0/50 [00:00<?, ? Portfolio Optimization/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import portfolio_optimizer\n",
    "from portfolio_optimizer import OptimalHoldings\n",
    "importlib.reload(portfolio_optimizer)\n",
    "\n",
    "returns = alpha_factors.FactorReturns(price_histories).factor_data\n",
    "dlyreturn_n_days_delay = 5\n",
    "delayed_returns = returns[-252:].shift(-dlyreturn_n_days_delay).dropna()\n",
    "start_date = list(delayed_returns.index)[0]\n",
    "end_date = list(delayed_returns.index)[-1]\n",
    "logger.info(f'OPT|{start_date}|{end_date}')\n",
    "current_holdings = pd.DataFrame(np.zeros(len(delayed_returns.columns)), index=delayed_returns.columns)\n",
    "init_port_value = portfolio_value = float(default_config['init_port_value'])\n",
    "min_viable_port_return = float(default_config['min_viable_port_return'])\n",
    "logger.info(f'OPT|INIT_PORT_VALUE|{init_port_value}')\n",
    "portfolio_growth = {}\n",
    "for opt_date in tqdm(delayed_returns.index.to_list()[-252::dlyreturn_n_days_delay], desc='Dates', unit=' Portfolio Optimization'):\n",
    "    alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "    risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "    est_return = delayed_returns.loc[opt_date]\n",
    "    optimal_weights = OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)\n",
    "    long_weights = optimal_weights[(100 * optimal_weights['optimalWeights']).round() > 0]\n",
    "    long_holdings = (long_weights['optimalWeights'] * portfolio_value).round(0)\n",
    "    new_holdings = long_holdings + (long_holdings * est_return[long_holdings.index])\n",
    "    portfolio_value = new_holdings.sum()\n",
    "    portfolio_growth[opt_date] = portfolio_value\n",
    "    current_holdings = new_holdings\n",
    "\n",
    "port_return = round(np.log(portfolio_value / init_port_value) * 100, 2)\n",
    "logger.info(f'OPT|INIT_PORT_VALUE|{init_port_value}|FINAL_PORT_VALUE|{portfolio_value}|PORT_RETURN|{port_return}%')\n",
    "if port_return >= min_viable_port_return:\n",
    "    logger.info(f'OPT|PROCEED|{port_return}')\n",
    "else:\n",
    "    logger.warn(f'OPT|STOP|{port_return}')\n",
    "    raise RuntimeError(f'Backtest indicates this strategy needs more work! ({port_return})') from None\n",
    "    \n",
    "pd.Series(portfolio_growth).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_return = round(np.log(portfolio_value / init_port_value) * 100, 2)\n",
    "logger.info(f'OPT|INIT_PORT_VALUE|{init_port_value}|FINAL_PORT_VALUE|{portfolio_value}|PORT_RETURN|{port_return}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(portfolio_growth).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_return = round(np.log(portfolio_value / init_port_value) * 100, 2)\n",
    "print(f'Starting portfolio: {init_port_value} Ending portfolio: {portfolio_value} Return: {port_return}%')\n",
    "if port_return >= 8:\n",
    "    print('Backtest indicates its okay to proceed with this strategy.')\n",
    "else:\n",
    "    raise RuntimeError(f'Backtest indicates this strategy needs more work! ({port_return})') from None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t] *",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
