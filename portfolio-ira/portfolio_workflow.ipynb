{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci-Kit version: 0.24.1\n",
      "Python version: 3.8.10\n",
      "Pandas version: 0.25.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "# Set the import path for the tools directiory\n",
    "import sys\n",
    "# insert at position 1 in the path, as 0 is the path of this file.\n",
    "sys.path.insert(1, '../tools')\n",
    "import importlib\n",
    "import ameritrade_functions as amc\n",
    "importlib.reload(amc)\n",
    "import trading_factors as alpha_factors\n",
    "importlib.reload(alpha_factors)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import nonoverlapping_estimator as ai_estimator\n",
    "importlib.reload(ai_estimator)\n",
    "\n",
    "print(f'Python version: {python_version()}')\n",
    "print(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Chromedriver\n",
    "from pathlib import Path\n",
    "chrome_executabel_path = str(Path.home()) + r'\\Anaconda Projects\\chromedriver\\chromedriver'\n",
    "\n",
    "# Make sure we have a data directory\n",
    "Path('./data').mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "# Which account are we interested in\n",
    "masked_account_number = '#---5311'\n",
    "account_portfolios_file_name = 'data/portfolio_data.csv'\n",
    "portfolio_file_name = 'data/portfolio_' + masked_account_number[-4:] + '.csv'\n",
    "price_histories_file_name = 'data/price_histories.csv'\n",
    "\n",
    "username, password, client_id = amc.configure_ameritrade('maiotradeuser', 'maiotradepw', 'maiotradeclientid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Generate Stock Universe\n",
    "\n",
    "- Gather stocks from specific criteria (SP500 top 50...)\n",
    "- Use stock sentiment to select stocks\n",
    "- Gather price histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Universe\n",
    "\n",
    "Here we setup the univers. This needs some work. The long term goal is to use a pipeline process to help select stock that are in the top 500 or something similare.\n",
    "\n",
    "For now we will use stocks from the portfolio, but stocks of interest (high news items), a list of well known stocks (this also has been augmented with some stocks that made Ameritrade's top 10 movers for a couple of days. This Ameritrade funciton has not been coded yet, but should be add down the line to automate pulling these tickers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History data\n",
    "\n",
    "One you have a set of investments you want to work with, you will need to pull some historical data for them.\n",
    "\n",
    "We will obtain 5 years of price histories. In the end this will provide us with 2 years of factor data since some of the factors are based on 1 year returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tickers:   0%|                                                                    | 0/505 [00:00<?, ?Finvis Postings/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks in universe: 505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tickers: 100%|██████████████████████████████████████████████████████████| 505/505 [02:04<00:00,  4.04Finvis Postings/s]\n",
      "News Tables: 100%|████████████████████████████████████████████████████| 503/503 [00:02<00:00, 214.65News Table Items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sentiment: 2.4816216396324764 with a standared deviation of: 1.7765738238477577 providing a cutoff of: 0.7050478157847186\n",
      "New number of stocks in universe: 436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d02707c4fe94e3d8b052d25b8e523a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tickers:   0%|          | 0/436 [00:00<?, ?Price Histories/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snp_500_stocks = utils.get_snp500()\n",
    "stock_universe = utils.reduce_universe_by_sentiment(set(snp_500_stocks.index.to_list()))\n",
    "number_of_years = 5\n",
    "price_histories = amc.AmeritradeRest(username, password, client_id).get_price_histories(stock_universe, datetime.today().strftime('%Y-%m-%d'), num_periods=number_of_years)\n",
    "utils.save_price_histories(price_histories, price_histories_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2a: Generate Alpha Factors using Stock Universe\n",
    "\n",
    "- Compute custom apha factors\n",
    "- Compute univeral quant factors\n",
    "- Compute date information\n",
    "- Save Alpha Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range for price histories: 2016-11-09 to 2021-11-09\n",
      "You have 436 stocks\n"
     ]
    }
   ],
   "source": [
    "print(f'Date range for price histories: {price_histories.date.min().date()} to {price_histories.date.max().date()}')\n",
    "close = utils.get_close_values(price_histories)\n",
    "sector_helper = utils.get_sector_helper(snp_500_stocks, 'GICS Sector', close.columns)\n",
    "print(f'You have {len(close.columns)} stocks')\n",
    "all_factors = pd.concat(\n",
    "[\n",
    "    alpha_factors.OvernightSentiment(price_histories, 5).rank().zscore().smoothed(10).rank().zscore().for_al(),\n",
    "    alpha_factors.FactorMeanReversion(price_histories, 5).demean(groupby=sector_helper.values()).rank().zscore().for_al(),\n",
    "    alpha_factors.AnnualizedVolatility(price_histories, 20).rank().zscore().for_al()\n",
    "], axis=1)\n",
    "all_factors.sort_index(inplace=True)\n",
    "all_factors = all_factors.dropna()\n",
    "\n",
    "all_factors.to_csv('data/all_factors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2b: Generate AI Alpha Factors\n",
    "\n",
    "- Compute target values (y)\n",
    "    - Quantize with 2 bins\n",
    "- Train model for Feature importance\n",
    "- Feature reduction\n",
    "- Train model for AI Alpha Vector\n",
    "- Compute AI Alpha Vectors for 1 year\n",
    "- Save AI Alpha Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the target values (y) and Shift back to create a 5 day forward prediciton\n",
    "\n",
    "This is something you want to experiment with. If you are planning on holding on to assets for long periods of time, perhaps a 20, 40 or 60 forward prediciton will work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors from date: 2016-11-16 00:00:00+00:00 to date: 2021-11-09 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "prod_target_source = '5Day2Quant'\n",
    "prod_target_quantiles = 2\n",
    "forward_prediciton_days = 5\n",
    "\n",
    "all_assets = all_factors.index.levels[1].values.tolist()\n",
    "print(f'Factors from date: {all_factors.index.levels[0].min()} to date: {all_factors.index.levels[0].max()}')\n",
    "features = all_factors.columns.tolist()\n",
    "\n",
    "all_factors = pd.concat(\n",
    "[\n",
    "    all_factors,\n",
    "    alpha_factors.FactorReturnQuantiles(price_histories, prod_target_quantiles, forward_prediciton_days).for_al(prod_target_source),\n",
    "], axis=1).dropna()\n",
    "all_factors.sort_index(inplace=True)\n",
    "\n",
    "all_factors['target'] = all_factors.groupby(level='ticker')[prod_target_source].shift(-forward_prediciton_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 10\n",
    "n_stocks = len(set(all_factors.index.get_level_values(level='ticker').values))\n",
    "clf_random_state = 42\n",
    "\n",
    "clf_parameters = {\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': n_days * n_stocks,\n",
    "    'oob_score': True,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': clf_random_state}\n",
    "n_trees_l = [50, 100, 250, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "temp = all_factors.dropna().copy()\n",
    "X = temp[features]\n",
    "y = temp['target']\n",
    "\n",
    "clf = RandomForestClassifier(1000, **clf_parameters)\n",
    "\n",
    "clf_nov = ai_estimator.NoOverlapVoter(clf, n_skip_samples=forward_prediciton_days-1)\n",
    "clf_nov.fit(X, y)\n",
    "\n",
    "print(f'train: {clf_nov.score(X, y.values)} oob: {clf_nov.oob_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_factors.evaluate_ai_alpha(all_factors, X, clf_nov, features, close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scores = alpha_factors.compute_ai_alpha_score(all_factors[features], clf_nov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_alpha = pd.DataFrame(alpha_scores, index=all_factors.index, columns=['AI_ALPHA']).reset_index()\n",
    "ai_alpha['date'] = ai_alpha['date'].dt.date\n",
    "alpha_vectors = ai_alpha.reset_index().pivot(index='date', columns='ticker', values='AI_ALPHA')\n",
    "alpha_vectors.reset_index().to_csv('data/alpha_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Generate Beta Factors\n",
    "\n",
    "- Use Risk Model\n",
    "- Compute Daily Betas for 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = alpha_factors.FactorReturns(price_histories).factor_data\n",
    "end_date = returns.index.max()\n",
    "start_date = end_date - pd.offsets.DateOffset(years=1)\n",
    "print(f'Generating 1 year Betas from {start_date} to {end_date}')\n",
    "beta_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "daily_betas = {}\n",
    "for beta_date in returns[start_date:].index:\n",
    "    start_of_returns = beta_date - pd.offsets.DateOffset(years=1) + pd.offsets.DateOffset(days=1) \n",
    "    beta_returns = returns.loc[start_of_returns:beta_date]\n",
    "    risk_model = alpha_factors.RiskModelPCA(beta_returns, 1, 20)\n",
    "    daily_betas[beta_date.strftime('%m/%d/%Y')] = risk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/daily_beta.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(daily_betas, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4a: Demonstrate using AI Alpha and Daily Betas to produce optiomal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_histories = utils.read_price_histories(price_histories_file_name)\n",
    "print(f'Date range for price histories: {price_histories.date.min().date()} to {price_histories.date.max().date()}')\n",
    "pricing = utils.get_close_values(price_histories)\n",
    "print(f'You have {len(pricing.columns)} stocks from picing')\n",
    "\n",
    "alpha_vectors = pd.read_csv('data/alpha_vectors.csv', parse_dates=['date']).set_index(['date']).sort_index()\n",
    "print(f'You have {len(alpha_vectors.columns)} stocks from alpha')\n",
    "\n",
    "with open('data/daily_beta.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    daily_betas = pickle.load(f)\n",
    "print(f'You have {len(daily_betas)} of daily betas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Daily Optimal Portfolios using 1 year of alpha and beta\n",
    "\n",
    "This first strategy is to use 2 day returns and optimize the portfolio daily.\n",
    "\n",
    "The second stragety is to use last day of the month returns and to optimize the portfolio monthly (or 20 day returns).\n",
    "\n",
    "Start with the last date, subtract 1 year to get the start and end dates for the betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import portfolio_optimizer\n",
    "from portfolio_optimizer import OptimalHoldings\n",
    "importlib.reload(portfolio_optimizer)\n",
    "\n",
    "risk_cap = 0.05\n",
    "weights_max = 0.24\n",
    "weights_min = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Day Strategy Backtest\n",
    "\n",
    "Use 5 Day returns and optimize portfolio weekly. \n",
    "\n",
    "We are looking for something at 8% return or better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "returns = alpha_factors.FactorReturns(price_histories).factor_data\n",
    "dlyreturn_n_days_delay = 5\n",
    "delayed_returns = returns[-251:].shift(-dlyreturn_n_days_delay).dropna()\n",
    "start_date = list(delayed_returns.index)[0]\n",
    "end_date = list(delayed_returns.index)[-1]\n",
    "print(f'Generating 1 year Optimal Portfolios from {start_date} to {end_date}')\n",
    "current_holdings = pd.DataFrame(np.zeros(len(delayed_returns.columns)), index=delayed_returns.columns)\n",
    "init_port_value = portfolio_value = 100000\n",
    "portfolio_growth = {}\n",
    "for opt_date in tqdm(delayed_returns.index.to_list()[-252::dlyreturn_n_days_delay], desc='Dates', unit='Portfolio Optimization'):\n",
    "    alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "    risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "    est_return = delayed_returns.loc[opt_date]\n",
    "    optimal_weights = OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)\n",
    "    long_weights = optimal_weights[(100 * optimal_weights['optimalWeights']).round() > 0]\n",
    "    long_holdings = (long_weights['optimalWeights'] * portfolio_value).round(0)\n",
    "    new_holdings = long_holdings + (long_holdings * est_return[long_holdings.index])\n",
    "    portfolio_value = new_holdings.sum()\n",
    "    portfolio_growth[opt_date] = portfolio_value\n",
    "    current_holdings = new_holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_return = round(np.log(portfolio_value / init_port_value) * 100, 2)\n",
    "print(f'Starting portfolio: {init_port_value} Ending portfolio: {portfolio_value} Return: {port_return}%')\n",
    "if port_return >= 8:\n",
    "    print('Backtest indicates its okay to proceed with this strategy.')\n",
    "else:\n",
    "    print('Backtest indicates this strategy needs more work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(portfolio_growth).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the last week to determine current portfolio mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_date = alpha_vectors.index[-2]\n",
    "print(f'From date: {opt_date}')\n",
    "risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "optimal_weights = OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_weights = optimal_weights[(100 * optimal_weights['optimalWeights']).round() > 5.0]\n",
    "returns[-252:][long_weights.index.to_list()].cumsum().plot()\n",
    "print(f'New portfolio variance is:  {risk_model.compute_portfolio_variance(optimal_weights):.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_and_scored_news = utils.get_finvis_stock_sentiment(long_weights.index.to_list()).sort_values(by='date')\n",
    "# Group by date and ticker columns from scored_news and calculate the mean\n",
    "mean_scores = parsed_and_scored_news.groupby(['ticker','date']).mean()\n",
    "# Unstack the column ticker\n",
    "mean_scores = mean_scores.unstack()\n",
    "# Get the cross-section of compound in the 'columns' axis\n",
    "mean_scores = mean_scores.xs('compound', axis=\"columns\").transpose()\n",
    "# Plot a bar chart with pandas\n",
    "mean_scores[-20:].plot(kind = 'bar')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First lets see which stocks we already own for a specific account\n",
    "\n",
    "I only want to work with Equity investments. This is kind of confusing, but at the account level assets that can be traded are call \"EQUITY\". When you get quotes for each asset, the same asset can be something like \"ETF\".\n",
    "\n",
    "I also use Ameritrade's portfolio planner tool to create an asset mix based off of their reccomendations. I don't want these stocks (or in my case mutual funds and ETFs) to be part of this analysis. So I'll remove them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Ameritrade Information\n",
    "\n",
    "Ameritrade credentials are stored in environment variables to keep from having unencrypted passwords stored on disk.\n",
    "\n",
    "The module automatically masks the account numbers to protect the actual accounts. An Ameritrade user can have many investment accounts. We will be working with only one for this demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication Tokens\n",
    "\n",
    "To get data from Ameritrade you will need to obtains a short time use token (there is a re-use token, but I have not coded it yet.) You only need to do this if you\n",
    "are going to use an existing Ameritrade account to define an initial set of stocks to analyze.\n",
    "\n",
    "To obtain a token, you will need to have a Chrome driver located somewhere on your system. This will allow the module to use your credentials to obtain an authentication token.\n",
    "\n",
    "For security reasons, I sugges using environment variables to store your credential information. If you store them in property files, or just code them into your notebook, you risk sharing the information with others if you use GitHub or some other SCCS. This also makes it easier to have them availabe from project to project in your development environment\n",
    "\n",
    "<span style=\"color:blue\">Note: *Account numbers are masked for security purposes.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade = amc.AmeritradeRest(username, password, client_id, chrome_executabel_path)\n",
    "td_ameritrade.authenticate()\n",
    "\n",
    "if len(td_ameritrade.authorization) == 0:\n",
    "    print('Error: No authorization data: {}'.format(td_ameritrade.authorization))\n",
    "else:\n",
    "    print('You have authorization')\n",
    "\n",
    "print(f'Date of trade: {datetime.today()}')\n",
    "\n",
    "# Specific Portfolio Account\n",
    "account_portfolio_df = utils.get_account_portfolio_data(td_ameritrade.parse_portfolios_list(), masked_account_number)\n",
    "equity_investments_df = utils.get_investments_by_type(account_portfolio_df, investment_type='EQUITY')\n",
    "print('Full Equity Portfolio:')\n",
    "display(equity_investments_df)\n",
    "\n",
    "long_term_stocks =  ['FGPHF', 'WKHS', 'EEENF', 'SCHF', 'VTIP', 'VGK', 'FNCL', 'SCHE', 'FSTA', 'SCHM', 'VWO', 'VTI', 'VBK', 'VXF', 'SCHA', 'VBR', 'VWOB']\n",
    "\n",
    "# Filter out non Equity investments\n",
    "current_stocks = amc.AmeritradeRest(username, password, client_id).get_quotes(utils.get_investment_symbols(equity_investments_df)).query('assetType == \"EQUITY\"').index.tolist()\n",
    "current_investments_df = equity_investments_df[~equity_investments_df['symbol'].isin(long_term_stocks)]\n",
    "print('Stocks to sell:')\n",
    "current_investments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and montior sell orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_cash_df = utils.get_investments_by_type(account_portfolio_df, investment_type='CASH_EQUIVALENT')\n",
    "print(available_cash_df.marketValue.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_cash = available_cash_df.marketValue.sum() + current_investments_df.marketValue.sum()\n",
    "print(f'Available cash  : {available_cash}')\n",
    "investment_base = 500\n",
    "investment_amount =  investment_base * round(available_cash / investment_base)\n",
    "print(f'Amount to invest: {investment_amount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial investment amount: {investment_amount}')\n",
    "nearest_base = 5\n",
    "long_quotes = amc.AmeritradeRest(username, password, client_id).get_quotes(long_weights.index.to_list())\n",
    "long_shares = long_quotes['regularMarketLastPrice'].to_frame()\n",
    "long_shares['invest_amount'] = (long_weights['optimalWeights'] * investment_amount).round(0)\n",
    "long_shares['est_shares'] = (long_shares['invest_amount'] / long_shares['regularMarketLastPrice'])\n",
    "long_shares['shares'] = nearest_base * round(long_shares['est_shares'] / nearest_base)\n",
    "long_shares['cost'] = long_shares['shares'] * long_shares['regularMarketLastPrice']\n",
    "print(f'Total cost: {long_shares.cost.sum()}')\n",
    "long_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place buy orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.today())\n",
    "long_quotes = amc.AmeritradeRest(username, password, client_id).get_quotes(long_weights.index.to_list())\n",
    "long_shares['current_price'] = long_quotes['regularMarketLastPrice']\n",
    "long_shares['actual_cost'] = long_shares.cost\n",
    "long_shares['current_amount'] = long_shares.shares * long_shares['current_price']\n",
    "long_shares['profit/loss'] = long_shares.current_amount - long_shares.actual_cost\n",
    "long_shares['returns'] = utils.compute_log_returns_days(long_shares.actual_cost, long_shares.current_amount) \n",
    "display(long_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_price_histories = amc.AmeritradeRest(username, password, client_id).get_price_histories(list(long_shares.index), datetime.today().strftime('%Y-%m-%d'), num_periods=number_of_years)\n",
    "portfolio_close = utils.get_close_values(portfolio_price_histories)\n",
    "utils.compute_log_returns(portfolio_close)[-5:].cumsum().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
