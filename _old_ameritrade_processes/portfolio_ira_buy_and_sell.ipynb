{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci-Kit version: 0.24.1\n",
      "Sci-Kit version: 0.24.1\n",
      "Python version: 3.8.8\n",
      "Pandas version: 1.3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import generate_alpha_beta_factors\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "# Set the import path for the tools directiory\n",
    "import sys\n",
    "# insert at position 1 in the path, as 0 is the path of this file.\n",
    "# sys.path.insert(1, './tools')\n",
    "import importlib\n",
    "import tools.ameritrade_functions as amc\n",
    "importlib.reload(amc)\n",
    "import tools.trading_factors_yahoo as alpha_factors\n",
    "importlib.reload(alpha_factors)\n",
    "import tools.utils as utils\n",
    "importlib.reload(utils)\n",
    "import tools.nonoverlapping_estimator as ai_estimator\n",
    "importlib.reload(ai_estimator)\n",
    "\n",
    "print(f'Python version: {python_version()}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Chromedriver\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure we have a data directory\n",
    "Path('./data').mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "# Which account are we interested in\n",
    "masked_account_number = '#---5311'\n",
    "account_portfolios_file_name = 'data/portfolio_data.csv'\n",
    "portfolio_file_name = 'data/portfolio_' + masked_account_number[-4:] + '.csv'\n",
    "price_histories_file_name = '../data/price_histories_yahoo.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assume price histories have been downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Alpha Factors using Stock Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 21:25:22,825|GenerateAlphaAndBeta|INFO|Python version: 3.8.8\n",
      "2022-10-04 21:25:22,825|GenerateAlphaAndBeta|INFO|Pandas version: 1.3.5\n",
      "2022-10-04 21:25:22,826|GenerateAlphaAndBeta|INFO|Pandas Data Reader version: 0.10.0\n",
      "2022-10-04 21:25:22,828|GenerateAlphaAndBeta|INFO|PRICE_HISTORIES_FILE|./data/price_histories_yahoo.csv...\n",
      "2022-10-04 21:25:23,878|GenerateAlphaAndBeta|INFO|PRICE_HISTORIES|2017-10-04 00:00:00|2022-10-03 00:00:00\n",
      "2022-10-04 21:25:23,878|GenerateAlphaAndBeta|INFO|Using 5 years of price history data to generate alpha factors.\n",
      "2022-10-04 21:25:23,894|GenerateAlphaAndBeta|INFO|PRICE_HISTORIES_ALPHA|2017-10-04 00:00:00|2022-10-03 00:00:00\n",
      "2022-10-04 21:25:23,897|GenerateAlphaAndBeta|INFO|STOCK_TICKERS|501\n",
      "2022-10-04 21:25:23,898|GenerateAlphaAndBeta|INFO|Gathering stock ticker sector data...\n",
      "2022-10-04 21:25:24,603|GenerateAlphaAndBeta|INFO|Stock sector information gathered.\n",
      "2022-10-04 21:25:25,376|GenerateAlphaAndBeta|INFO|USED_FACTOR|trailing_overnight_returns_10_day_smoothed\n",
      "2022-10-04 21:25:25,377|GenerateAlphaAndBeta|INFO|USED_FACTOR|market_dispersion_120_day\n",
      "2022-10-04 21:25:25,377|GenerateAlphaAndBeta|INFO|USED_FACTOR|market_volatility_120_day\n",
      "2022-10-04 21:25:25,379|GenerateAlphaAndBeta|INFO|Combining 3 alphas into one dataframe...\n",
      "2022-10-04 21:26:03,467|GenerateAlphaAndBeta|INFO|ALPHA_FACTORS_FILE|./data/all_factors.csv\n",
      "2022-10-04 21:26:07,772|GenerateAlphaAndBeta|INFO|Alpha factors saved.\n",
      "2022-10-04 21:26:07,772|GenerateAlphaAndBeta|INFO|ALPHA_FACTOR|trailing_overnight_returns_10_day_smoothed\n",
      "2022-10-04 21:26:07,772|GenerateAlphaAndBeta|INFO|ALPHA_FACTOR|market_dispersion_120_day\n",
      "2022-10-04 21:26:07,772|GenerateAlphaAndBeta|INFO|ALPHA_FACTOR|market_volatility_120_day\n",
      "2022-10-04 21:26:07,779|GenerateAlphaAndBeta|INFO|Generate beta factors...\n",
      "2022-10-04 21:26:07,823|GenerateAlphaAndBeta|INFO|Generating 4 year Betas from 2018-10-03 00:00:00 to 2022-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dates: 100%|██████████████████████████████████████████████████████████████| 1007/1007 [00:38<00:00, 26.35 Daily Beta/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 21:26:46,039|GenerateAlphaAndBeta|INFO|BETA_FACTORS_FILE|./data/daily_beta.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_alpha_beta_factors.generate_alpha_beta_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2b: Generate AI Alpha Factors\n",
    "\n",
    "- Compute target values (y)\n",
    "    - Quantize with 2 bins\n",
    "- Train model for Feature importance\n",
    "- Feature reduction\n",
    "- Train model for AI Alpha Vector\n",
    "- Compute AI Alpha Vectors for 1 year\n",
    "- Save AI Alpha Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the target values (y) and Shift back to create a 5 day forward prediciton\n",
    "\n",
    "This is something you want to experiment with. If you are planning on holding on to assets for long periods of time, perhaps a 20, 40 or 60 forward prediciton will work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_target_source = '5Day2Quant'\n",
    "prod_target_quantiles = 2\n",
    "forward_prediciton_days = 5\n",
    "\n",
    "all_assets = all_factors.index.levels[1].values.tolist()\n",
    "print(f'Factors from date: {all_factors.index.levels[0].min()} to date: {all_factors.index.levels[0].max()}')\n",
    "features = all_factors.columns.tolist()\n",
    "\n",
    "all_factors = pd.concat(\n",
    "[\n",
    "    all_factors,\n",
    "    alpha_factors.FactorReturnQuantiles(price_histories, prod_target_quantiles, forward_prediciton_days).for_al(prod_target_source),\n",
    "], axis=1).dropna()\n",
    "all_factors.sort_index(inplace=True)\n",
    "\n",
    "all_factors['target'] = all_factors.groupby(level=1)[prod_target_source].shift(-forward_prediciton_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 10\n",
    "n_stocks = len(set(all_factors.index.get_level_values(level=1).values))\n",
    "clf_random_state = 42\n",
    "\n",
    "clf_parameters = {\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': n_days * n_stocks,\n",
    "    'oob_score': True,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': clf_random_state}\n",
    "n_trees_l = [50, 100, 250, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "temp = all_factors.dropna().copy()\n",
    "X = temp[features]\n",
    "y = temp['target']\n",
    "\n",
    "clf = RandomForestClassifier(1000, **clf_parameters)\n",
    "\n",
    "clf_nov = ai_estimator.NoOverlapVoter(clf, n_skip_samples=forward_prediciton_days-1)\n",
    "clf_nov.fit(X, y)\n",
    "\n",
    "print(f'train: {clf_nov.score(X, y.values)} oob: {clf_nov.oob_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_alpha_name = 'AI_ALPHA'\n",
    "factors_with_alpha = alpha_factors.add_alpha_score(all_factors[features].copy(), clf_nov, ai_alpha_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_with_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_to_compare = ['trailing_overnight_returns_10_day_smoothed', 'mean_reversion_120_day_logret', 'annualzed_volatility_120_day', 'average_dollar_volume_120_day']\n",
    "alpha_factors.evaluate_ai_alpha(factors_with_alpha[factors_to_compare + [ai_alpha_name]], close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_alpha = factors_with_alpha[ai_alpha_name].copy()\n",
    "alpha_vectors = ai_alpha.reset_index().pivot(index='Date', columns='Symbols', values=ai_alpha_name)\n",
    "alpha_vectors.reset_index().to_csv('data/alpha_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "logging.config.fileConfig('./config/logging.ini')\n",
    "logger = logging.getLogger('GenerateAlphaAndBeta')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "default_config = config[\"DEFAULT\"]\n",
    "\n",
    "alpha_factors_file_name = default_config['DataDirectory'] + '/' + default_config['AlphaFactorsFileName']\n",
    "logger.info(f'ALPHA_FACTORS_FILE|{alpha_factors_file_name}')\n",
    "all_factors = pd.read_csv(alpha_factors_file_name, parse_dates=['Date']).set_index(['Date', 'Symbols']).sort_index()\n",
    "logger.info('Alpha factors read.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Generate Beta Factors\n",
    "\n",
    "- Use Risk Model\n",
    "- Compute Daily Betas for 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = alpha_factors.FactorReturns(price_histories).factor_data.dropna()\n",
    "end_date = returns.index.max()\n",
    "start_date = end_date - pd.offsets.DateOffset(years=number_of_years - 1)\n",
    "print(f'Generating {number_of_years - 1} year Betas from {start_date} to {end_date}')\n",
    "beta_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "daily_betas = {}\n",
    "for beta_date in tqdm(returns[start_date:].index, desc='Beta Dates', unit='Generate Daily Betas'):\n",
    "    start_of_returns = beta_date - pd.offsets.DateOffset(years=1)\n",
    "    beta_returns = returns.loc[start_of_returns:beta_date]\n",
    "    risk_model = alpha_factors.RiskModelPCA(beta_returns, 1, 20)\n",
    "    daily_betas[beta_date.strftime('%m/%d/%Y')] = risk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/daily_beta.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(daily_betas, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4a: Demonstrate using AI Alpha and Daily Betas to produce optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_histories = pd.read_csv(price_histories_file_name, header=[0, 1], index_col=[0], parse_dates=True, low_memory=False)\n",
    "print(f'Date range for price histories: {price_histories.index.min()} to {price_histories.index.max()}')\n",
    "pricing = price_histories.Close\n",
    "print(f'You have {len(pricing.columns)} stocks from picing')\n",
    "\n",
    "alpha_vectors = pd.read_csv('data/alpha_vectors.csv', parse_dates=['Date']).set_index(['Date']).sort_index()\n",
    "print(f'You have {len(alpha_vectors.columns)} stocks from alpha')\n",
    "\n",
    "with open('data/daily_beta.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    daily_betas = pickle.load(f)\n",
    "print(f'You have {len(daily_betas)} of daily betas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Daily Optimal Portfolios using 1 year of alpha and beta\n",
    "\n",
    "This first strategy is to use 2 day returns and optimize the portfolio daily.\n",
    "\n",
    "The second stragety is to use last day of the month returns and to optimize the portfolio monthly (or 20 day returns).\n",
    "\n",
    "Start with the last date, subtract 1 year to get the start and end dates for the betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import portfolio_optimizer\n",
    "from portfolio_optimizer import OptimalHoldings\n",
    "importlib.reload(portfolio_optimizer)\n",
    "\n",
    "risk_cap = 0.30\n",
    "weights_max = 0.5\n",
    "weights_min = 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Day Strategy Backtest\n",
    "\n",
    "Use 5 Day returns and optimize portfolio weekly. \n",
    "\n",
    "We are looking for something at 8% return or better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "returns = alpha_factors.FactorReturns(price_histories).factor_data\n",
    "dlyreturn_n_days_delay = forward_prediciton_days\n",
    "delayed_returns = returns[-252:].shift(-dlyreturn_n_days_delay).dropna()\n",
    "start_date = list(delayed_returns.index)[0]\n",
    "end_date = list(delayed_returns.index)[-1]\n",
    "print(f'Generating 1 year Optimal Portfolios from {start_date} to {end_date}')\n",
    "current_holdings = pd.DataFrame(np.zeros(len(delayed_returns.columns)), index=delayed_returns.columns)\n",
    "init_port_value = portfolio_value = 100000\n",
    "portfolio_growth = {}\n",
    "for opt_date in tqdm(delayed_returns.index.to_list()[-252::dlyreturn_n_days_delay], desc='Dates', unit='Portfolio Optimization'):\n",
    "    alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "    risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "    est_return = delayed_returns.loc[opt_date]\n",
    "    optimal_weights = OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)\n",
    "    long_weights = optimal_weights[(100 * optimal_weights['optimalWeights']).round() > 0]\n",
    "    long_holdings = (long_weights['optimalWeights'] * portfolio_value).round(0)\n",
    "    new_holdings = long_holdings + (long_holdings * est_return[long_holdings.index])\n",
    "    portfolio_value = new_holdings.sum()\n",
    "    portfolio_growth[opt_date] = portfolio_value\n",
    "    current_holdings = new_holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(portfolio_growth).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_return = round(np.log(portfolio_value / init_port_value) * 100, 2)\n",
    "print(f'Starting portfolio: {init_port_value} Ending portfolio: {portfolio_value} Return: {port_return}%')\n",
    "if port_return >= 8:\n",
    "    print('Backtest indicates its okay to proceed with this strategy.')\n",
    "else:\n",
    "    raise RuntimeError(f'Backtest indicates this strategy needs more work! ({port_return})') from None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the last week to determine current portfolio mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_date = alpha_vectors.index[-1]\n",
    "print(f'From date: {opt_date}')\n",
    "risk_model = daily_betas[opt_date.strftime('%m/%d/%Y')]\n",
    "alpha_vector = pd.DataFrame(alpha_vectors.loc[opt_date])\n",
    "optimal_weights = OptimalHoldings(risk_cap=risk_cap,weights_max=weights_max, weights_min=weights_min).find(alpha_vector, risk_model.factor_betas_, risk_model.factor_cov_matrix_, risk_model.idiosyncratic_var_vector_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_weights = optimal_weights[(100 * optimal_weights['optimalWeights']).round() > 5.0]\n",
    "returns[-252:][long_weights.index.to_list()].cumsum().plot()\n",
    "print(f'New portfolio variance is:  {risk_model.compute_portfolio_variance(optimal_weights):.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "td_ameritrade.authenticate()\n",
    "td_ameritrade.get_fundamental(list(long_weights.index.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_and_scored_news = utils.get_finvis_stock_sentiment(long_weights.index.to_list()).sort_values(by='date')\n",
    "# Group by date and ticker columns from scored_news and calculate the mean\n",
    "mean_scores = parsed_and_scored_news.groupby(['ticker','date']).mean()\n",
    "# Unstack the column ticker\n",
    "mean_scores = mean_scores.unstack()\n",
    "# Get the cross-section of compound in the 'columns' axis\n",
    "mean_scores = mean_scores.xs('compound', axis=\"columns\").transpose()\n",
    "# Plot a bar chart with pandas\n",
    "mean_scores[-20:].plot(kind = 'bar')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First lets see which stocks we already own for a specific account\n",
    "\n",
    "I only want to work with Equity investments. This is kind of confusing, but at the account level assets that can be traded are call \"EQUITY\". When you get quotes for each asset, the same asset can be something like \"ETF\".\n",
    "\n",
    "I also use Ameritrade's portfolio planner tool to create an asset mix based off of their reccomendations. I don't want these stocks (or in my case mutual funds and ETFs) to be part of this analysis. So I'll remove them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Ameritrade Information\n",
    "\n",
    "Ameritrade credentials are stored in environment variables to keep from having unencrypted passwords stored on disk.\n",
    "\n",
    "The module automatically masks the account numbers to protect the actual accounts. An Ameritrade user can have many investment accounts. We will be working with only one for this demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication Tokens\n",
    "\n",
    "To get data from Ameritrade you will need to obtains a short time use token (there is a re-use token, but I have not coded it yet.) You only need to do this if you\n",
    "are going to use an existing Ameritrade account to define an initial set of stocks to analyze.\n",
    "\n",
    "To obtain a token, you will need to have a Chrome driver located somewhere on your system. This will allow the module to use your credentials to obtain an authentication token.\n",
    "\n",
    "For security reasons, I sugges using environment variables to store your credential information. If you store them in property files, or just code them into your notebook, you risk sharing the information with others if you use GitHub or some other SCCS. This also makes it easier to have them availabe from project to project in your development environment\n",
    "\n",
    "<span style=\"color:blue\">Note: *Account numbers are masked for security purposes.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "td_ameritrade.authenticate()\n",
    "\n",
    "if len(td_ameritrade.authorization) == 0:\n",
    "    print('Error: No authorization data: {}'.format(td_ameritrade.authorization))\n",
    "else:\n",
    "    print('You have authorization')\n",
    "\n",
    "print(f'Date of trade: {datetime.today()}')\n",
    "\n",
    "# Specific Portfolio Account\n",
    "account_portfolio_df = utils.get_account_portfolio_data(td_ameritrade.parse_portfolios_list(), masked_account_number)\n",
    "equity_investments_df = utils.get_investments_by_type(account_portfolio_df, investment_type='EQUITY')\n",
    "print('Full Equity Portfolio:')\n",
    "display(equity_investments_df)\n",
    "\n",
    "long_term_stocks =  ['FGPHF', 'WKHS', 'EEENF']\n",
    "\n",
    "# Filter out non Equity investments\n",
    "current_stocks = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid').get_quotes(\n",
    "    utils.get_investment_symbols(equity_investments_df)).query('assetType == \"EQUITY\"').index.tolist()\n",
    "stocks_to_sell = equity_investments_df[~equity_investments_df['symbol'].isin(long_term_stocks)]\n",
    "print('Stocks to sell:')\n",
    "stocks_to_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade.parse_portfolios_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade.get_fundamental(list(stocks_to_sell.symbol.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_portfolio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_to_sell.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and montior sell orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "td_ameritrade.authenticate()\n",
    "td_ameritrade.parse_portfolios_list()\n",
    "account_number = td_ameritrade.unmask_account(masked_account_number)\n",
    "sell_result = td_ameritrade.place_bulk_sell_orders(account_number, stocks_to_sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "    td_ameritrade.authenticate()\n",
    "    account_portfolio_df = utils.get_account_portfolio_data(td_ameritrade.parse_portfolios_list(), masked_account_number)\n",
    "    equity_investments_df = utils.get_investments_by_type(account_portfolio_df, investment_type='EQUITY')\n",
    "    stocks_with_sell_orders = equity_investments_df[~equity_investments_df['symbol'].isin(long_term_stocks)]\n",
    "    if len(stocks_with_sell_orders[stocks_with_sell_orders.longQuantity >= 1]) == 0:\n",
    "        break\n",
    "    print(f'\\r{datetime.today()} - Stocks to sell: {stocks_with_sell_orders.symbol.values}', end='           ')\n",
    "    time.sleep(60)\n",
    "    \n",
    "print(f'\\r{datetime.today()} - All stocks sold: {stocks_to_sell.symbol.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_balances = td_ameritrade.parse_accounts().loc[masked_account_number]\n",
    "print(account_balances)\n",
    "print(account_balances.currentBalances_cashBalance)\n",
    "print(account_balances.currentBalances_moneyMarketFund)\n",
    "available_cash = account_balances.currentBalances_cashBalance + account_balances.currentBalances_moneyMarketFund\n",
    "print(f'Total cash to invest: {available_cash}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Available cash  : {available_cash}')\n",
    "investment_base = 1000\n",
    "investment_amount = math.floor(available_cash / investment_base) * investment_base\n",
    "print(f'Amount to invest: {investment_amount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.today())\n",
    "print(f'Initial investment amount: {investment_amount}')\n",
    "nearest_base = 5\n",
    "min_shares = 5\n",
    "long_quotes = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid').get_quotes(long_weights.index.to_list())\n",
    "long_shares = long_quotes['regularMarketLastPrice'].to_frame()\n",
    "long_shares['optimalWeights'] = long_weights['optimalWeights']\n",
    "long_shares['invest_amount'] = (long_shares['optimalWeights'] * investment_amount).round(0)\n",
    "long_shares['shares'] = (long_shares['invest_amount'] / long_shares['regularMarketLastPrice']).astype(int)\n",
    "display(long_shares)\n",
    "\n",
    "# Remove symbols that are less than min and re-compute\n",
    "\n",
    "final_long_shares = long_shares.query('shares >= @min_shares').copy()\n",
    "final_long_shares['optimalWeights'] = final_long_shares['optimalWeights'] / final_long_shares['optimalWeights'].sum(axis=0)\n",
    "final_long_shares['invest_amount'] = (final_long_shares['optimalWeights'] * investment_amount).round(0)\n",
    "final_long_shares['shares'] = (final_long_shares['invest_amount'] / final_long_shares['regularMarketLastPrice']).astype(int)\n",
    "final_long_shares['cost'] = final_long_shares['shares'] * final_long_shares['regularMarketLastPrice']\n",
    "display(final_long_shares)\n",
    "print(f'Total cost: {final_long_shares.cost.sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place buy orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid').get_quotes(long_weights.index.to_list())\n",
    "td_ameritrade.get_fundamental(list(final_long_shares.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.today())\n",
    "td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "td_ameritrade.authenticate()\n",
    "td_ameritrade.parse_portfolios_list()\n",
    "account_number = td_ameritrade.unmask_account(masked_account_number)\n",
    "\n",
    "for index, row in final_long_shares.iterrows():\n",
    "    fundamental = td_ameritrade.get_fundamental([index])\n",
    "    print(f'Placing BUY order on {account_number} for {row.shares} shares of {index}:{fundamental.loc[0].assetType}...')\n",
    "    result = td_ameritrade.place_order(account_number, index, fundamental.loc[0].assetType, row.shares, 'BUY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_price_histories = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid').get_price_histories(list(long_shares.index), datetime.today().strftime('%Y-%m-%d'), num_periods=number_of_years)\n",
    "portfolio_close = utils.get_close_values(portfolio_price_histories)\n",
    "utils.compute_log_returns(portfolio_close)[-2:].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ameritrade_functions as amc\n",
    "importlib.reload(amc)\n",
    "\n",
    "td_ameritrade = amc.AmeritradeRest('maiotradeuser', 'maiotradepw', 'maiotradeclientid')\n",
    "td_ameritrade.authenticate()\n",
    "td_ameritrade.parse_accounts().loc[masked_account_number]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
