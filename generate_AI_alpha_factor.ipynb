{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-01 15:00:05,409|numexpr.utils|INFO|NumExpr defaulting to 4 threads.\n",
      "Sci-Kit version: 0.24.1\n",
      "Sci-Kit version: 0.24.1\n",
      "2022-05-01 15:00:09,011|GenerateAIAlphaFactor|INFO|Python version: 3.8.8\n",
      "2022-05-01 15:00:09,011|GenerateAIAlphaFactor|INFO|Pandas version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "logging.config.fileConfig('./config/logging.ini')\n",
    "logger = logging.getLogger('GenerateAIAlphaFactor')\n",
    "\n",
    "import configparser\n",
    "from platform import python_version\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the import path for the project tools directiory\n",
    "import sys\n",
    "# insert at position 1 in the path, as 0 is the path of this file.\n",
    "sys.path.insert(1, 'tools')\n",
    "\n",
    "# Project imports\n",
    "import importlib\n",
    "import trading_factors_yahoo as alpha_factors\n",
    "importlib.reload(alpha_factors)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import nonoverlapping_estimator as ai_estimator\n",
    "importlib.reload(ai_estimator)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "logger.info(f'Python version: {python_version()}')\n",
    "logger.info(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('./config/config.ini')\n",
    "default_config = config['AIAlpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price History data and Alphs Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-01 15:11:43,531|GenerateAIAlphaFactor|INFO|PRICE_HISTORIES_FILE|./data/price_histories_yahoo.csv...\n",
      "2022-05-01 15:11:44,590|GenerateAIAlphaFactor|INFO|PRICE_HISTORIES|2017-05-01 00:00:00|2022-04-29 00:00:00\n",
      "2022-05-01 15:11:44,591|GenerateAIAlphaFactor|INFO|Using 5 years of price history data to generate alpha factors.\n",
      "2022-05-01 15:11:44,608|GenerateAIAlphaFactor|INFO|PRICE_HISTORIES_ALPHA|2017-05-01 00:00:00|2022-04-29 00:00:00\n",
      "2022-05-01 15:11:44,614|GenerateAIAlphaFactor|INFO|STOCK_TICKERS|502\n",
      "2022-05-01 15:11:44,615|GenerateAIAlphaFactor|INFO|ALPHA_FACTORS_FILE|./data/all_factors.csv\n",
      "2022-05-01 15:11:45,462|GenerateAIAlphaFactor|INFO|Alpha factors read.\n",
      "2022-05-01 15:11:45,462|GenerateAIAlphaFactor|INFO|ALPHA_FACTOR|momentum_252_day\n",
      "2022-05-01 15:11:45,462|GenerateAIAlphaFactor|INFO|ALPHA_FACTOR|trailing_overnight_returns_10_day_smoothed\n",
      "2022-05-01 15:11:45,462|GenerateAIAlphaFactor|INFO|ALPHA_FACTOR|mean_reversion_120_day_logret\n",
      "2022-05-01 15:11:45,466|GenerateAIAlphaFactor|INFO|ALPHA_FACTOR|annualzed_volatility_20_day\n"
     ]
    }
   ],
   "source": [
    "price_histories_file_name = default_config['DataDirectory'] + '/' + default_config['PriceHistoriesFileName']\n",
    "logger.info(f'PRICE_HISTORIES_FILE|{price_histories_file_name}...')\n",
    "price_histories = pd.read_csv(price_histories_file_name, header=[0, 1], index_col=[0], parse_dates=True, low_memory=False)\n",
    "logger.info(f'PRICE_HISTORIES|{price_histories.index.min()}|{price_histories.index.max()}')\n",
    "logger.info(f'Using {default_config[\"NumberOfYearsForAlpha\"]} years of price history data to generate alpha factors.')\n",
    "latest_date = price_histories.index.max() \n",
    "earliest_date = latest_date - pd.DateOffset(years=int(default_config[\"NumberOfYearsForAlpha\"]))\n",
    "price_histories = price_histories[(price_histories.index >= earliest_date) & (price_histories.index <= latest_date)]\n",
    "logger.info(f'PRICE_HISTORIES_ALPHA|{price_histories.index.min()}|{price_histories.index.max()}')\n",
    "close = price_histories.Close\n",
    "logger.info(f'STOCK_TICKERS|{len(close.columns)}')\n",
    "alpha_factors_file_name = default_config['DataDirectory'] + '/' + default_config['AlphaFactorsFileName']\n",
    "\n",
    "logger.info(f'ALPHA_FACTORS_FILE|{alpha_factors_file_name}')\n",
    "all_factors = pd.read_csv(alpha_factors_file_name, parse_dates=['Date']).set_index(['Date', 'Symbols']).sort_index()\n",
    "logger.info('Alpha factors read.')\n",
    "\n",
    "for alpha_factor in all_factors.columns:\n",
    "    logger.info(f'ALPHA_FACTOR|{alpha_factor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2b: Generate AI Alpha Factor\n",
    "\n",
    "- Compute target values (y)\n",
    "    - Quantize with 2 bins\n",
    "- Train model for Feature importance\n",
    "- Feature reduction\n",
    "- Train model for AI Alpha Vector\n",
    "- Compute AI Alpha Vectors for 1 year\n",
    "- Save AI Alpha Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute the target values (y) and Shift back to create a 5 day forward prediciton\n",
    "\n",
    "This is something you want to experiment with. If you are planning on holding on to assets for long periods of time, perhaps a 20, 40 or 60 forward prediciton will work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-01 15:11:48,244|GenerateAIAlphaFactor|INFO|Setting 5 days-2 quantiles to target 5Day2Quant\n",
      "2022-05-01 15:11:48,246|GenerateAIAlphaFactor|INFO|Factors from date: 2018-05-01 00:00:00 to date: 2022-04-29 00:00:00\n",
      "2022-05-01 15:12:12,055|GenerateAIAlphaFactor|INFO|Creating training and label data...\n",
      "2022-05-01 15:12:12,129|GenerateAIAlphaFactor|INFO|TRAINING_FEATURE|momentum_252_day\n",
      "2022-05-01 15:12:12,129|GenerateAIAlphaFactor|INFO|TRAINING_FEATURE|trailing_overnight_returns_10_day_smoothed\n",
      "2022-05-01 15:12:12,129|GenerateAIAlphaFactor|INFO|TRAINING_FEATURE|mean_reversion_120_day_logret\n",
      "2022-05-01 15:12:12,129|GenerateAIAlphaFactor|INFO|TRAINING_FEATURE|annualzed_volatility_20_day\n",
      "2022-05-01 15:12:12,132|GenerateAIAlphaFactor|INFO|TRAINING_DATASET|503506|LABEL_DATASET|503506\n"
     ]
    }
   ],
   "source": [
    "forward_prediciton_days = int(default_config['ForwardPredictionDays'])\n",
    "prod_target_quantiles = int(default_config['PredictionQuantiles'])\n",
    "prod_target_source = f'{forward_prediciton_days}Day{prod_target_quantiles}Quant'\n",
    "\n",
    "logger.info(f'Setting {forward_prediciton_days} days-{prod_target_quantiles} quantiles to target {prod_target_source}')\n",
    "all_assets = all_factors.index.levels[1].values.tolist()\n",
    "logger.info(f'Factors from date: {all_factors.index.levels[0].min()} to date: {all_factors.index.levels[0].max()}')\n",
    "features = all_factors.columns.tolist()\n",
    "\n",
    "training_factors = pd.concat(\n",
    "[\n",
    "    all_factors,\n",
    "    alpha_factors.FactorReturnQuantiles(price_histories, prod_target_quantiles, forward_prediciton_days).for_al(prod_target_source),\n",
    "], axis=1).dropna()\n",
    "training_factors.sort_index(inplace=True)\n",
    "\n",
    "training_factors['target'] = training_factors.groupby(level=1)[prod_target_source].shift(-forward_prediciton_days)\n",
    "\n",
    "logger.info(f'Creating training and label data...')\n",
    "temp = training_factors.dropna().copy()\n",
    "X = temp[features]\n",
    "y = temp['target']\n",
    "for feature in features:\n",
    "    logger.info(f'TRAINING_FEATURE|{feature}')\n",
    "logger.info(f'TRAINING_DATASET|{len(X)}|LABEL_DATASET|{len(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-01 15:15:52,082|GenerateAIAlphaFactor|INFO|Creating RandomForestClassifier with 10000 trees...\n",
      "2022-05-01 15:15:52,083|GenerateAIAlphaFactor|INFO|Parameter: criterion set to entropy\n",
      "2022-05-01 15:15:52,084|GenerateAIAlphaFactor|INFO|Parameter: min_samples_leaf set to 5020\n",
      "2022-05-01 15:15:52,085|GenerateAIAlphaFactor|INFO|Parameter: oob_score set to True\n",
      "2022-05-01 15:15:52,086|GenerateAIAlphaFactor|INFO|Parameter: n_jobs set to -1\n",
      "2022-05-01 15:15:52,086|GenerateAIAlphaFactor|INFO|Parameter: random_state set to 42\n",
      "2022-05-01 15:15:52,087|GenerateAIAlphaFactor|INFO|Creating Non-Overalpping Voter with 4 non-overlapping windows...\n",
      "2022-05-01 15:15:52,089|GenerateAIAlphaFactor|INFO|Training classifier...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_days = 10\n",
    "n_stocks = len(set(all_factors.index.get_level_values(level=1).values))\n",
    "clf_random_state = 42\n",
    "\n",
    "clf_parameters = {\n",
    "    'criterion': 'entropy',\n",
    "    'min_samples_leaf': n_days * n_stocks,\n",
    "    'oob_score': True,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': clf_random_state}\n",
    "\n",
    "n_trees = int(default_config['RandomForestNTrees'])\n",
    "\n",
    "logger.info(f'Creating RandomForestClassifier with {n_trees} trees...')\n",
    "for key, value in clf_parameters.items():\n",
    "    logger.info(f'Parameter: {key} set to {value}')\n",
    "clf = RandomForestClassifier(n_trees, **clf_parameters)\n",
    "\n",
    "logger.info(f'Creating Non-Overalpping Voter with {forward_prediciton_days-1} non-overlapping windows...')\n",
    "clf_nov = ai_estimator.NoOverlapVoter(clf, n_skip_samples=forward_prediciton_days-1)\n",
    "\n",
    "logger.info(f'Training classifier...')\n",
    "clf_nov.fit(X, y)\n",
    "\n",
    "logger.info(f'CLASSIFER|TRAIN|{clf_nov.score(X, y.values)}|OOB|{clf_nov.oob_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_alpha_name = default_config['AIAlphaName']\n",
    "factors_with_alpha = alpha_factors.add_alpha_score(training_factors[features].copy(), clf_nov, ai_alpha_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_with_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_to_compare = features\n",
    "alpha_factors.evaluate_ai_alpha(factors_with_alpha[factors_to_compare + [ai_alpha_name]], close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_alpha = factors_with_alpha[ai_alpha_name].copy()\n",
    "alpha_vectors = ai_alpha.reset_index().pivot(index='Date', columns='Symbols', values=ai_alpha_name)\n",
    "alpha_vectors.reset_index().to_csv('data/alpha_vectors.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4t] *",
   "language": "python",
   "name": "conda-env-ml4t-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
